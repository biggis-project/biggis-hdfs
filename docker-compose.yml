version: '2.1'

services:
  hdfs-name:
    image: biggis/hdfs:2.7.1
    container_name: hdfs-name
    ports:
      - "50070:50070"
      - "8020:8020"
    command: start.sh name
    environment:
      USER_ID: ${USER_ID-1000}
      USER_NAME: hdfs
      HADOOP_MASTER_ADDRESS: hdfs-name
      TIMEZONE: Europe/Berlin
    networks:
        - hdfs
      # volumes:
    #   - hdfs-data:/data/hdfs

  hdfs-sname:
    image: biggis/hdfs:2.7.1
    container_name: hdfs-sname
    depends_on:
        - hdfs-name
    ports:
      - "50090:50090"
    command: start.sh sname
    environment:
      USER_ID: ${USER_ID-1000}
      USER_NAME: hdfs
      HADOOP_MASTER_ADDRESS: hdfs-name
      TIMEZONE: Europe/Berlin
    networks:
        - hdfs    
    # volumes:
    #   - hdfs-data:/data/hdfs

  hdfs-data:
    image: biggis/hdfs:2.7.1
    depends_on:
        - hdfs-name
    expose:
      - "50010"
      - "50075"
    command: start.sh data
    environment:
      USER_ID: ${USER_ID-1000}
      USER_NAME: hdfs
      HADOOP_MASTER_ADDRESS: hdfs-name
      TIMEZONE: Europe/Berlin
    networks:
        - hdfs
#     volumes:
#       - hdfs-data:/data/hdfs

  api:
    build:
        context: ./
        dockerfile: ./Dockerfile.api
    image: hdfs-api:0.0.2
    container_name: hdfs-api
    depends_on:
      - hdfs-name
      - hdfs-data
    ports:
      - "3000:3000"
    command: npm start
    environment:
      HADOOP_MASTER_ADDRESS: hdfs-name
      USERNAME: hdfs
      PASSWORD: password
    networks:
        - hdfs

# volumes:
#   hdfs-data:

networks:
    hdfs:
        driver: bridge
